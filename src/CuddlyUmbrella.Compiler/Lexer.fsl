{

module Lexer

open Microsoft.FSharp.Text.Lexing
open System.Text
open CuddlyUmbrella.Compiler
open Parser


let lexeme = LexBuffer<_>.LexemeString
let newline (lexbuf: LexBuffer<_>) = lexbuf.StartPos <- lexbuf.StartPos.NextLine

}

let char        = ['a'-'z' 'A'-'Z']   
let digit       = ['0'-'9']   
let identifier  = char(char|digit|['_'])* 
let type_spec   = "void" | "int" | "float" | "bool" | "string"
let bool        = "true" | "false"
let int         = digit+
let float       = digit+'.'digit+
let whitespace  = [' ' '\t' ]
let newline     = ('\n' | '\r' '\n')
let punctuation = [',' ':' ';' '(' ')' '{' '}' '"']
let operator    = "+" | "-" | "=" | "<" | ">" | "<=" | ">=" | "<-"

rule tokenize = parse
// --------------------------
| whitespace            { tokenize lexbuf }
| newline               { newline lexbuf; tokenize lexbuf }
| type_spec             { TYPE_SPEC(lexeme lexbuf) }
| bool                  { BOOL(System.Boolean.Parse(lexeme lexbuf)) }
| int                   { INT(System.Int32.Parse(lexeme lexbuf)) }
| float                 { FLOAT(System.Single.Parse(lexeme lexbuf)) }
| '"'                   { string (new StringBuilder(16)) lexbuf }
| identifier            { ParserUtils.keywordOrIdentifierToken (lexeme lexbuf) }
| punctuation           { ParserUtils.punctuationToken (lexeme lexbuf) }
| operator              { ParserUtils.operatorToken (lexeme lexbuf) }
// --------------------------
| _                     { failwith ("Lexer error on lexeme: " + lexeme lexbuf) }
| eof                   { EOF }


and string builder = parse
// --------------------------
| '"'                   { STRING(builder.ToString()) }
| '\\' '\\'             { string (builder.Append("\\")) lexbuf }
| '\\' '\"'             { string (builder.Append("\"")) lexbuf }
| [^ '"' '\\']+         { string (builder.Append(lexeme lexbuf)) lexbuf }
// --------------------------
| _                     { failwith ("Lexer error on lexeme: "+ lexeme lexbuf) }
| eof                   { failwith ("Unterminated string literal") }


{

let getAllTokens lexbuf =
    let rec aux acc cur =
        match cur with
        | EOF -> acc @ [EOF]
        | tok -> aux (acc @ [tok]) (tokenize lexbuf)
    
    aux [] (tokenize lexbuf)

}
